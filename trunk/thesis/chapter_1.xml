<?xml version="1.0" encoding="utf-8" ?>
<chapter id="chapter_1">

  <title>Automatic memory management</title>
  
  <sect1 id="chapter_1-sect-1">
    <para>Computer software is getting more and more complex. Software 
    projects of today, while equal in actual scope, are far more ambitious
    in their goals than those of the IBM OS/360 project to which Frederick 
    Brooks relates in his seminal work 
    "The Mythical Man-Month"<xref linkend="brooks-1975"/>. While software 
    engineering as a field is better understood now than it was in the
    mid-sixties, you will find few researchers in the field claiming that this
    understanding has kept up with the growth in the complexity of software 
    projects.</para>
    
    <para>In fact, in a world where Visual Basic is one of the most popular
    programming languages, one can easily argue that the developer pool has a 
    larger portion of relatively unskilled programmers now than ever. Yet, 
    some of the software even from this segment has complexity requirements
    that would leave the Fred Brooks anno 1965 dumbfounded. And while not all
    of this software will stand as shiny examples of software engineering, 
    it is hard to deny the fact that software written by unskilled 
    developers plays an important part in our society. </para>
    
    <para>While software engineering hasn't quite been able to meet
    the expectations once held for it (one constantly sees figures of up
    to 80% failure in software projects TODO), it is obvious that something
    has enabled programmers to build more and more complex software. And if
    this "something" isn't a vastly increased understanding of the art and 
    science of software engineering, what is it?</para>
    
    <para>The answer is simple: the tools and languages we use today
    are orders of magnitude better than what the developers under Brooks
    had available. OS/360 was written wholly in assembly code, which was
    (and still is) hard to write and debug, mainly because of its lack of
    abstraction and its conceptual distance from the problem domain.</para>
    
    <para>In contrast, we have today at our disposal a vast array
    of very high level languages. Languages like Visual Basic, Python, Java
    and C# maintain a high level of abstraction from the actual hardware, and
    often come with massive standard libraries that enables the developer
    to focus on the core functionality of his application, rather than 
    constantly having to reinvent the wheel. 
    </para>
    
    <para>While the availability of high quality standard libraries go a long
    way in explaining the increased productivity of todays' developers, it is 
    hardly the only reason. One other feature the aforementioned languages all
    have in common is that they free the developer from the responsibility of
    manually managing memory. Memory related bugs are all too common in
    traditional lower-level languages (who has never accessed a pointer whose
    backing memory has been freed<footnote><para>This is commonly referred
    to as a "dangling" pointer.</para></footnote>?), and tracking down these
    bugs can take up an inordinate amount of developer time, especially in more
    complex software. The newer languages basically makes this a non-issue by
    handling the allocation and de-allocation of memory in the language
    runtime, thus relieving the developer of this rather tedious burden.</para> 
    
    <para>And while hard core C/C++ developers still maintain, in some kind of 
     misunderstood machismo, that memory management "is too important to be 
     left to the computer"<footnote><para>It is a long-standing joke:
     C programmers have long understood that memory management is so critical
     it can't be left up to the system, and Lisp programmers have long understood
     that memory management is so critical, it can't be left up to the 
     programmers. TODO-source</para></footnote> it is becoming more and more
     clear that automatic memory management, in various implementations, is
     here to stay. The past couple of years have seen a steady shift towards
     the use of higher level programming languages and tools for all but the 
     most low-level of development tasks (operating systems, drivers, 3D graphics 
     engines etc.) And the higher level languages all invariably support 
     automatic memory management.</para>       
  </sect1>
  
  <sect1 id="chapter_1-sect-2">
    <title>Garbage collection</title>
    <para>Automatic memory management is commonly referred to as <firstterm>garbage 
    collection</firstterm>, referring to how the mechanism automatically picks
    up the garbage after the programmer. The word "garbage" in this context refers
    to objects that are no longer in use by the program.</para>
    
    <para>While the previous section portrayed garbage collection as a new trend
    in programming languages, it actually has a history almost as long as that 
    of high level programming itself. In fact, the second high level programming
    language ever created, Lisp, sported a garbage collector already in its
    initial specification in 1960<xref linkend="mccarthy-1960"/>. Subsequent
    versions of Lisp, including Scheme and Common Lisp, have all included
    various forms of garbage collectors. It is hard to conceive of a language
    in the extended Lisp family (functional languages) featuring manual memory
    management, due to the dynamic nature of their runtime environments.</para>
    
    <para>The language Smalltalk, developed by Alan Kay and others in the 70s,
    also included garbage collection as a central element. Again, this was
    necessitated by a highly dynamice runtime environment. </para>   
    
    
    <para>Garbage collectors have long had a bad reputation among developers
    focussing on raw performance as the primary goal, and they were mostly
    considered an unneeded luxury by programmers developing in languages like
    C and C++. Garbage collection by the system would often be a 
    time-consuming operation, and would cause noticeable pauses during 
    program execution. Many programmers felt that this was a waste of system
    resources and that they would be better off managing memory manually.</para>
    
    <para>This has changed in later years for several reasons: Computer
    hardware is now faster than it ever was (and is still getting faster, 
    despite dire predictions of the opposite), making the aforementioned
    pauses far less noticeable, and there has been a lot of research effort 
    into creating ever better algorithms for effective garbage collection. It is 
    now perfectly conceivable to implement soft real-time applications (f.ex
    games) in a garbage collected language.</para>
    
    <para>The concept of garbage collection is usually an inherent feature of 
    the language in question. As mentioned earlier, functional languages like 
    Lisp would be hard to conceive without some kind of automatic memory 
    management. Very high level languages, those often referred to as 
    "scripting" languages (Python, Perl etc...), would also be hard to imagine
    having manual memory management. Garbage collection is, for this reason,
    often an integral part of a language's formal specification. </para>
    
    <para>There are two major forms of garbage collection. </para>
    
    <sect2>
      <title>Tracing garbage collectors</title>
      
      <para>A tracing garbage collector operates on the principle that
      an object that cannot be reached from any other reachable object in the 
      system is garbage. It determines this by building a graph of object 
      references starting from a set of well-known <firstterm>roots</firstterm>.
      These roots usually include local variables and static/global fields.
      Any object that is <emphasis>not</emphasis> found in this graph is 
      considered garbage and is cleaned up by the system.</para>
      
      <para>Cleaning up means, in simple implementations, merely to mark the
      memory previously occupied by the object as vacant and available for future
      memory allocations. Such a simple scheme has the same problem a traditional
      memory allocation function like <function>malloc()</function> has: the
      memory heap used for the allocations will get fragmented, and it requires
      quite a lot of bookkeeping merely to keep track of the occupied and vacant
      areas of the heap. New allocations will have to search through the heap
      in order to find a section of memory large enough to accommodate the 
      request. In some cases, there may not be a single segment in the heap 
      large enough to fit the new object even if the total available amount of
      memory far exceeds the demands.</para>
      
      <sect3>
      
      <title>Compacting garbage collectors</title>
      
      <para>For this reason, most real garbage collectors also <firstterm>
        compact</firstterm> the heap when performing a garbage collection. Heap
        compaction in this context means that all <emphasis>live</emphasis>
        objects are copied to and placed together in a single continuous
        segment of memory. Dead objects are not copied. This makes subsequent
        memory allocations a very simple operation. The allocator can just
        maintain a pointer to the end of this segment, and whenever a request
        for memory comes in, it can satisfy this request by just returning the
        value of this pointer and incrementing it. A <function>new</function>
        statement then merely becomes a pointer increment. This is orders of
        magnitude faster than a traditional <function>malloc()</function>
        implementation.</para> <para>This scheme also has the added benefit of
        increased locality. Related objects will be placed close to each other
        in memory, something that makes it far more likely that the processor
        can maintain them in one of its caches.</para>
      
      </sect3>
      
      <sect3>
      
        <title>Generational garbage collectors</title> 
        
        <para>Of course, this scheme requires that a lot of memory is copied
        around. Additionally, pointers to the objects in the old locations need
        to be backpatched to point to the new locations. These can be
        time-consuming operations.</para>
        
        <para>A generational garbage collector exploits the fact that most 
        objects have a relatively short life. To do this, it divides the heap
        into 2 or more <firstterm>generations</firstterm>. Objects are 
        initially allocated in the first generation. If an object survives a
        garbage collection, it is copied or <firstterm>promoted</firstterm> 
        into the next generation. When working in this manner, it can restrict
        garbage collection runs to a single generation, which can be collected
        very quickly. Full garbage collections, spanning all generations, 
        only need to be performed every once in a while.</para>
      
      </sect3>
    </sect2>
    
    <sect2>
      <title>Reference counting</title>
      <para>Another form of garbage collection, although not commonly referred
      to as such, is <firstterm>reference counting.</firstterm> In this scheme, 
      each object maintains a count of how many other objects are referring to 
      it. For every time another object obtains a reference to this object, the
      other object is responsible for incrementing this count. Likewise, each
      time a reference goes out of scope or the object is no longer needed, 
      this count needs to be decremented by one.</para>
      
      <para>Obviously, this mechanism breaks down in the case where two 
      objects reference one another, either directly or indirectly. This is 
      called a <firstterm>cycle</firstterm>. Traditional reference counting 
      mechanisms are unable to deal with this case. Languages and environments
      depending on reference counting either supplement the mechanism with a 
      tracing garbage collector or mandate that cycles are not permitted.</para>
      
      <para>Reference counting can be either explicit or implicit. In an 
      environment that uses implicit reference counting, reference counts are 
      incremented and decremented automatically as a side effect of variable
      assignments. Explicit reference counting requires the programmer to 
      explicitly call functions or methods that adjust the reference count.</para>
    </sect2>
  
  </sect1>
    
    
  
</chapter>
