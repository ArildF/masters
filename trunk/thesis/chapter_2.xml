<?xml version="1.0" encoding="utf-8"?>
<chapter id="chapter_2">
  <title>Automatic memory management</title>
  <sect1 id="chapter_2-sect-2">
    <title>Garbage collection</title>
    <para>Automatic memory management is commonly referred to as <firstterm>garbage 
    collection</firstterm>, referring to how the mechanism automatically picks
    up the garbage after the programmer. The word "garbage" in this context refers
    to objects that are no longer in use by the program.</para>
    
    <para>While the previous section portrayed garbage collection as a new trend
    in programming languages, it actually has a history almost as long as that 
    of high level programming itself. In fact, the second high level programming
    language ever created, Lisp, sported a garbage collector already in its
    initial specification in 1960<xref linkend="mccarthy-1960"/>. Subsequent
    versions of Lisp, including Scheme and Common Lisp, have all included
    various forms of garbage collectors. It is hard to conceive of a language
    in the extended Lisp family (functional languages) featuring manual memory
    management, due to the dynamic nature of their runtime environments.</para>
    
    <para>The language Smalltalk, developed by Alan Kay and others in the 70s,
    also included garbage collection as a central element. Again, this was
    necessitated by a highly dynamice runtime environment. </para>   
    
    
    <para>Garbage collectors have long had a bad reputation among developers
    focussing on raw performance as the primary goal, and they were mostly
    considered an unneeded luxury by programmers developing in languages like
    C and C++. Garbage collection by the system would often be a 
    time-consuming operation, and would cause noticeable pauses during 
    program execution. Many programmers felt that this was a waste of system
    resources and that they would be better off managing memory manually.</para>
    
    <para>This has changed in later years for several reasons: Computer
    hardware is now faster than it ever was (and is still getting faster, 
    despite dire predictions of the opposite), making the aforementioned
    pauses far less noticeable, and there has been a lot of research effort 
    into creating ever better algorithms for effective garbage collection. It is 
    now perfectly conceivable to implement soft real-time applications (f.ex
    games) in a garbage collected language.</para>
    
    <para>The concept of garbage collection is usually an inherent feature of 
    the language in question. As mentioned earlier, functional languages like 
    Lisp would be hard to conceive without some kind of automatic memory 
    management. Very high level languages, those often referred to as 
    "scripting" languages (Python, Perl etc...), would also be hard to imagine
    having manual memory management. Garbage collection is, for this reason,
    often an integral part of a language's formal specification. </para>
    
    <para>There are two major forms of garbage collection. </para>
    
    <sect2 id="chapter_2-sect-2.1">
      <title>Tracing garbage collectors</title>
      
      <para>A tracing garbage collector operates on the principle that
      an object that cannot be reached from any other reachable object in the 
      system is garbage. It determines this by building a graph of object 
      references starting from a set of well-known <firstterm>roots</firstterm>.
      These roots usually include local variables and static/global fields.
      Any object that is <emphasis>not</emphasis> found in this graph is 
      considered garbage and is cleaned up by the system.</para>
      
      <para>Cleaning up means, in simple implementations, merely to mark the
      memory previously occupied by the object as vacant and available for future
      memory allocations. Such a simple scheme has the same problem a traditional
      memory allocation function like <function>malloc()</function> has: the
      memory heap used for the allocations will get fragmented, and it requires
      quite a lot of bookkeeping merely to keep track of the occupied and vacant
      areas of the heap. New allocations will have to search through the heap
      in order to find a section of memory large enough to accommodate the 
      request. In some cases, there may not be a single segment in the heap 
      large enough to fit the new object even if the total available amount of
      memory far exceeds the demands.</para>
      
      <sect3 id="chapter_2-sect-2.1.1">
      
      <title>Compacting garbage collectors</title>
      
      <para>For this reason, most real garbage collectors also <firstterm>
        compact</firstterm> the heap when performing a garbage collection. Heap
        compaction in this context means that all <emphasis>live</emphasis>
        objects are copied to and placed together in a single continuous
        segment of memory. Dead objects are not copied. This makes subsequent
        memory allocations a very simple operation. The allocator can just
        maintain a pointer to the end of this segment, and whenever a request
        for memory comes in, it can satisfy this request by just returning the
        value of this pointer and incrementing it. A <function>new</function>
        statement then merely becomes a pointer increment. This is orders of
        magnitude faster than a traditional <function>malloc()</function>
        implementation.</para> <para>This scheme also has the added benefit of
        increased locality. Related objects will be placed close to each other
        in memory, something that makes it far more likely that the processor
        can maintain them in one of its caches.</para>
      
      </sect3>
      
      <sect3 id="chapter_2-sect-2.1.2">
      
        <title>Generational garbage collectors</title> 
        
        <para>Of course, this scheme requires that a lot of memory is copied
        around. Additionally, pointers to the objects in the old locations need
        to be backpatched to point to the new locations. These can be
        time-consuming operations.</para>
        
        <para>A generational garbage collector exploits the fact that most 
        objects have a relatively short life. To do this, it divides the heap
        into 2 or more <firstterm>generations</firstterm>. Objects are 
        initially allocated in the first generation. If an object survives a
        garbage collection, it is copied or <firstterm>promoted</firstterm> 
        into the next generation. When working in this manner, it can restrict
        garbage collection runs to a single generation, which can be collected
        very quickly. Full garbage collections, spanning all generations, 
        only need to be performed every once in a while.</para>
      
      </sect3>
    </sect2>
    
    <sect2 id="chapter_2-sect-2.2">
      <title>Reference counting</title>
      <para>Another form of garbage collection, although not commonly referred
      to as such, is <firstterm>reference counting.</firstterm> In this scheme, 
      each object maintains a count of how many other objects are referring to 
      it. For every time another object obtains a reference to this object, the
      other object is responsible for incrementing this count. Likewise, each
      time a reference goes out of scope or the object is no longer needed, 
      this count needs to be decremented by one.</para>
      
      <para>Obviously, this mechanism breaks down in the case where two 
      objects reference one another, either directly or indirectly. This is 
      called a <firstterm>cycle</firstterm>. Traditional reference counting 
      mechanisms are unable to deal with this case. Languages and environments
      depending on reference counting either supplement the mechanism with a 
      tracing garbage collector or mandate that cycles are not permitted.</para>
      
      <para>Reference counting can be either explicit or implicit. In an 
      environment that uses implicit reference counting, reference counts are 
      incremented and decremented automatically as a side effect of variable
      assignments. Explicit reference counting requires the programmer to 
      explicitly call functions or methods that adjust the reference count.</para>
      
      <para>The choice of implicit or reference counting is not necessarily an 
      either/or, even within a single language/technology. Some languages 
      accessing COM objects (which are reference counted) use implicit 
      reference counting, while others again use explicit. Languages like
      Visual Basic 6 are examples of the former, while C/C++ are the most 
      common examples of the latter.</para>      
      
    </sect2>
      
  </sect1>
  
  <sect1 id="chapter_2-sect-3">
  
    <title>Advantages and disadvantages of the two models</title>
    <para>Obviously, the two schemes of automatic memory management both have 
    their benefits and disadvantages (otherwise, there wouldn't be two 
    disparate models in the first place!).</para>
    
    <para>Advantages of tracing garbage collectors include:</para>
    
    <variablelist>
    
      <varlistentry>
        <term>Programming simplicity</term>
        <listitem>
          <para>Programming in an environment that provides a tracing garbage
          collector is very simple; usually you can just allocate objects and 
          forget about them. The garbage collector will deal with unreachable
          objects.</para>
        </listitem>
      </varlistentry>    
      
      <varlistentry>
        <term>Locality of reference</term>
        <listitem>
          <para>The allocation strategies of most implementations of garbage 
          collectors (allocating a new object is often just a matter of 
          incrementing a pointer) will usually lead to related objects being
          located close to one another in memory. This leads to a greater 
          chance of objects being in the CPU's cache when accessing them from
          methods of other objects, as well as reducing the program's working 
          set and reducing the number of page faults associated with the 
          program.</para>
        </listitem>
      </varlistentry>
    
    </variablelist>
    
    <para>Among the disadvantages, we find:</para>
    
    <variablelist>
      
      <varlistentry>
        <term>No deterministic destruction</term>
        <listitem>
          <para>It is not possible to determine <emphasis>when</emphasis> an
          object under the control of a garbage collector is destroyed. In
          quite a few cases, such objects hold onto external resources such as
          files, operating system synchronization primitives, window handles
          etc... Some of these resources are in short supply, and should be
          disposed of as soon as possible. It is then obvious that we cannot 
          rely on the garbage collector to release these for us in a timely 
          fashioon, necessitating an explicit <function>Close()</function> or
          <function>Dispose()</function> method.</para>
        </listitem>
      </varlistentry>
      
      <varlistentry>
        <term>Unpredictable runtime behavior</term>
        <listitem>
          <para>A tracing garbage collector is not entirely predictable; it 
          might decide to stop and perform a collection at any time. 
          Furthermore, a full collection might take a relatively long time to 
          perform, causing the program to pause while it is running. Although
          faster hardware and better garbage collection algorithms have gone a 
          long way in mitigating this factor in later years, there is still a 
          widespread perception (justified or not) of this being a major issue.
          </para>
        </listitem>
      </varlistentry>
    </variablelist>
    
    <para>The benefits of reference counting are the same as the drawbacks of
    tracing collectors:</para>
    
    <variablelist>
    
      <varlistentry>
        <term>Deterministic destruction</term>
        <listitem>
          <para>Given the source code of a program using a reference counted
          memory management solution, one can determine the exact sequence 
          point in execution where an object is destroyed. This ensures the
          timely destruction of external resources held onto by these objects.
         </para>
        </listitem>
      </varlistentry>
      
      <varlistentry>
        <term>Predictable runtime behavior</term>
        <listitem>
          <para>A reference counted mechanism has predictable execution time;
          there are no long nondeterministic pauses. An object is removed at 
          the exact moment it becomes garbage.</para>
        </listitem>
      </varlistentry>
      
    </variablelist>
    
    <para>Of course, nothing is perfect:</para>
    
    <variablelist>
    
      <varlistentry>
        <term>Reference counts take up space</term>
        <listitem>
          <para>Every reference counted object needs to have a field
          containing the reference count. In most cases this implies an 
          overhead of 4 bytes per object.</para>
        </listitem>
      </varlistentry>
      
      <varlistentry>
        <term>Reference counting takes time</term>
        <listitem>
          <para>For every time a reference counted object is assigned to 
          another reference variable or passed to a function, the reference 
          count needs to be updated. The time spent doing this kind of 
          housekeeping is likely to be greater than the amortized time spent 
          doing collections in a tracing collector.</para>
        </listitem>
      </varlistentry>
    </variablelist>
  </sect1>

</chapter>
