<?xml version="1.0" encoding="utf-8" ?>
<chapter id="chapter_1">

  <title>Introduction</title>
  
  <sect1 id="chapter_1-sect-1">
    <title>The complexity of software</title>
    <para>Computer software is getting more and more complex. Software 
    projects of today, while equal in actual scope, are far more ambitious
    in their goals than those of the IBM OS/360 project to which Frederick 
    Brooks relates in his seminal work 
    <quote>The Mythical Man-Month</quote><xref linkend="brooks-1975"/>. While
    software engineering as a field is better understood now than it was in the
    mid-sixties, you will find few researchers in the field claiming that this
    understanding has kept up with the growth in the complexity of software 
    projects.</para>
    
    <para>In fact, in a world where Visual Basic remains one of the most popular
    programming languages, one can easily argue that the developer pool has a 
    larger portion of relatively unskilled programmers now than ever. Yet, 
    some of the software even from this segment has complexity requirements
    that would leave the Fred Brooks anno 1965 dumbfounded. And while not all
    of this software will stand as shiny examples of software engineering, 
    it is hard to deny the fact that software written by unskilled 
    developers plays an important part in our society. </para>
    
    <para>While software engineering hasn't quite been able to meet
    the expectations once held for it, it is obvious that something
    has enabled programmers to build increasingly more complex software. And if
    this <quote>something</quote> isn't a vastly increased understanding of the 
    art and science of software engineering, what is it?</para>
    
   <para>The answer is complex and probably worth of a thesis or two of its
    own, but one thing is certain: the tools and languages we use today are
    orders of magnitude better than what the developers under Brooks
    had available. OS/360 was written wholly in assembly code, which was
    (and still is) hard to write and debug, mainly because of its lack of
    abstraction and its conceptual distance from the problem domain. Fred 
    Brooks himself mentioned the advent of higher level programming languages
    as one of the things most likely to advance the field of software 
    engineering <footnote><para>Likewise, in his retrospective essay 
    <quote>No Silver Bullet</quote><xref linkend="brooks-1987"/>, he 
    mentions object-oriented programming as one of the things that indeed came 
    closest to being a <quote>silver bullet</quote>.</para></footnote>.</para>
    
    <para>In contrast to the situation in Brooks' day, we currently have at our
    disposal a vast array of very high level languages. Languages like Visual
    Basic, Python, Java and C# maintain a high level of abstraction from the
    actual hardware, and often come with massive standard libraries that
    enables the developer to focus on the core functionality of his
    application, rather than constantly having to reinvent the wheel. </para>
    
    <para>While the availability of high quality standard libraries go a long
    way in explaining the increased productivity of todays' developers, it is 
    hardly the only reason. One other feature the aforementioned languages all
    have in common is that they free the developer from the responsibility of
    manually managing memory. Memory related bugs are all too common in
    traditional lower-level languages (who has never accessed a pointer whose
    backing memory has been freed<footnote><para>This is commonly referred
    to as a "dangling" pointer.</para></footnote>?), and tracking down these
    bugs can take up an inordinate amount of developer time, especially in more
    complex software. The newer languages basically make this a non-issue by
    handling the allocation and de-allocation of memory in the language
    runtime, thus relieving the developer of this rather tedious burden.</para> 
    
    <para>And while hard core C/C++ developers still maintain, in some kind of 
     misunderstood machismo, that memory management "is too important to be 
     left to the computer"<footnote><para>It is a long-standing joke:
     C programmers have long understood that memory management is so critical
     it can't be left up to the system, and Lisp programmers have long understood
     that memory management is so critical, it can't be left up to the 
     programmers.</para></footnote> it is becoming more and more
     clear that automatic memory management, in various implementations, is
     here to stay. The past couple of years have seen a steady shift towards
     the use of higher level programming languages and tools for all but the 
     most low-level of development tasks (operating systems, drivers, 3D graphics 
     engines etc.) And the higher level languages all invariably support 
     automatic memory management.</para>       
  </sect1>  
  
  <sect1>
    <title>The Common Language Runtime</title>
    <para>Enter the Common Language Runtime (CLR): A rich execution engine that
    provides services and support for a wide variety of computer languages,
    ranging from low level ones, such as C and C++, to very high level languages
    such as IronPython, Nemerle and Boo. However, any language that targets the
    CLR is pretty much confined to the memory model provided by the execution 
    engine. </para>
    
    <para>This model, based on a tracing garbage collector, is in its very 
    nature undeterministic: it provides no guarantees as to when an object 
    will be marked as garbage and disposed of. If the object holds onto 
    resources not related to memory, such as file handles and other items in
    scarce supply, disposing of an object at the earliest possible moment 
    might be crucial in order to attain the maximum possible performance.</para>
    
    <para>To illustrate, an example might be in order:</para>
    <example>
      <title>Memory pressure</title>
      <programlisting><![CDATA[
for (int i = 0; i < 42000; i++)
{
   LargeObject obj = new LargeObject();
   obj.DoStuff();
}      
      ]]></programlisting>      
    </example>   
    
    <para>In the above code, 42000 instances of the 
    <classname>LargeObject</classname> is created inside a tight loop. Now, what 
    happens at the end brace? Is the object created inside the loop disposed of,
    releasing the memory allocated and any unmanaged resources associated with 
    it? In the CLR, the answer is no. New instances of <classname>LargeObject</classname> 
    will continue to be allocated, but the old ones will linger up until the
    time when the garbage collector runs out of space to allocate the new
    ones.</para> 
    
    <para>If <quote>Large</quote> in <classname>LargeObject</classname> does 
    not refer to the actual amount of heap memory allocated for the object, but
    another resource held by it, this might take a long time. Consider the case
    where you have a class like this:</para> 
    
    <example>
      <title>A type holding onto an expensive unmanaged resource</title>
      <programlisting><![CDATA[
class LargeObject
{
  Foo()
  {
    this.expensiveUnmanagedResource = AcquireResource();
  }
  
  ~LargeObject()
  {
     FreeResource(this.expensiveUnmanagedResource);
  }
  
  // ...
  
  private IntPtr expensiveUnmanagedResource; 
 
} 

      ]]></programlisting>      
    </example>   
    <para>In this case, objects of the <classname>LargeObject</classname> type
    only occupy 4 bytes of heap memory, plus whatever memory is required for 
    internal bookkeeping by the execution engine. We will assume the latter 
    number is 8 bytes, leaving us with 12 bytes per object. Now, the garbage 
    collector should be able to allocate 42000 * 12 = 504 000 bytes on the heap
    without even breaking a sweat, and a garbage collection might not occur at
    all in the timeframe of the loop. But this does not take into account the
    cost of the unmanaged resource. If
    <structfield>expensiveUnmanagedResource</structfield> represents a file
    handle, the underlying operating system will run out of these a long time
    before the garbage collector runs out of memory on one of its heaps.</para>
    
    <para>I will in this thesis investigate the feasibility of introducing a 
    hybrid model of memory management in the CLR, one in which certain objects
    can be tracked by a reference counting mechanism instead of the tracing 
    garbage collector. If <classname>LargeObject</classname> was managed by
    reference counting instead of the CLR's garbage collector, each instance
    would be destroyed and its unmanaged resource released at the end of each
    iteration of the loop.</para>
    
    <para>The reason for choosing a hybrid model over a pure reference counted
    mechanism lies in the fact that reference counting implementations have 
    drawbacks of their own: they can be inefficient in terms of execution time 
    and memory, and they do not handle cycles (in which an object directly or
    indirectly holds a reference to itself) well. There are existing languages
    that use a hybrid mechanism, of which the most notable is the Python 
    programming language<xref linkend="python-language"/>, but the 
    implementation aimed for in this paper differs from these in that the 
    tracing garbage collector will remain the primary memory management 
    mechanism, leaving reference counting for specific scenarios in which they
    are generally useful.</para>
    
    <para>Another reason for going with a hybrid is the number of implicit 
    assumptions made in the CLR regarding the memory model. For example, there
    is a class in the <firstterm>Base Class Libraries</firstterm> named 
    <classname>GC</classname>, which allows the programmer to have some control
    over the tracing garbage collector directly. To completely replace the 
    memory management model of the CLR would require either removing this 
    class entirely (which would technically violate the ECMA standard 
    describing the CLR) or making its methods into no-ops.</para>
    
    <para>The primary vehicle for the implementation of such a mechanism in 
    the CLR will be the <firstterm>Shared Source CLI</firstterm> (SSCLI), a
    source implementation of the CLR released by Microsoft. My thesis will
    focus on determining which changes need to be made to the SSCLI in order to
    support an hybrid memory management model as described above. </para>
    
    <para>The SSCLI consists of a large amount of code, and considerable time
    will have to be spent in getting acquainted with it in order to complete
    this implementation. This paper will therefore describe the workings of the
    SSCLI in some detail, as well as going into the workings of the current 
    tracing garbage collector in some detail.</para>
    
  </sect1>  
  
</chapter>
